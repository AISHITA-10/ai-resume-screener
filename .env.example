## Copy to .env and fill values
#
# Local / free LLM via Ollama
# - Install Ollama from: https://ollama.com
# - In a terminal, run:  ollama pull llama3.1
# - Then ensure the Ollama server is running (ollama serve, usually automatic).
USE_OLLAMA=1
OLLAMA_MODEL=llama3.1
#
# If neither OpenAI nor Ollama is available, the app still works in
# "no-LLM" mode and returns evidence-only summaries.
#
# App storage:
DATA_DIR=.data
